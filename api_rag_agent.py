from src.vector_stores import VectorStoreManager
#æœ¬åœ° qwen_embeddings
# from qwen_embeddings import QwenSentenceTransformerEmbeddings
from langchain.chains import LLMChain
from langchain.prompts import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)

from langchain.memory import ConversationBufferMemory
import json
import os
import re
from typing import Optional
from pydantic import SecretStr
from src.llm_factory import LLMFactory
from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse
import uvicorn

class ApiRagAgent:
    def __init__(self):
        # åˆå§‹åŒ–å‘é‡å­˜å‚¨ä¸é‡æ’åºå™¨
        self.embeddings = LLMFactory.create_embeddings(provider='dashscope')
        self.vsm = VectorStoreManager(embeddings=self.embeddings)
        self.vsm.load_vector_store(collection_name="api_docs")

        # åˆå§‹åŒ–æ™ºè°±åƒé—®ï¼ˆGLM-4ï¼‰æ¨¡å‹
        self.llm = LLMFactory.create_llm(provider='dashscope')
        # åˆå§‹åŒ–è®°å¿†ï¼ˆå­˜å‚¨å¯¹è¯å†å²ï¼‰
        self.memory = ConversationBufferMemory()

        # æç¤ºè¯æ¨¡æ¿ - è¦æ±‚æ¨¡å‹åªè¿”å›çº¯ JSON
        self.prompt_template = ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template(
                """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æ¥å£åŠ©æ‰‹ï¼Œç›®æ ‡æ˜¯æ ¹æ®ç”¨æˆ·éœ€æ±‚å’Œæ¥å£æ–‡æ¡£ï¼Œç›´æ¥è¿”å›ä¸€ä¸ª JSON è¯·æ±‚ä½“ï¼Œç¬¦åˆåç«¯æ¥å£è°ƒç”¨è§„èŒƒã€‚

        æ¥å£ä¿¡æ¯å¦‚ä¸‹ï¼š
        åç§°: {name}
        æè¿°: {description}
        æ–¹æ³•: {method}
        åœ°å€: {endpoint}
        å‚æ•°è¯´æ˜: {params_json}

        è¯·æ ¹æ®ç”¨æˆ·è¾“å…¥æ„é€ è°ƒç”¨è¯·æ±‚ä½“ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
        {{ 
        "method": "GET" | "POST" | "DELETE" | "PUT",
        "path": "/api/xxx/{{{{id}}}} æˆ– /api/xxx",
        "body": {{ ... }}  // å¯é€‰ï¼Œä»…POST/PUTæ‰éœ€è¦
        }}

        è¯·éµå¾ªä»¥ä¸‹è¦æ±‚ï¼š
        1. ç›´æ¥è¿”å› JSON å¯¹è±¡ï¼Œä¸éœ€è¦è§£é‡Šè¯´æ˜
        2. ä»…è¾“å‡º JSONï¼Œä¸éœ€è¦ä½¿ç”¨ markdown ä»£ç å—
        3. è‹¥ç”¨æˆ·å‚æ•°ä¸å…¨ï¼Œä»…è¾“å‡ºå·²æœ‰å­—æ®µå’Œä¸€ä¸ª "missing" å­—æ®µï¼Œåˆ—å‡ºç¼ºå¤±å­—æ®µåï¼ˆå­—ç¬¦ä¸²æ•°ç»„ï¼‰

        ç¤ºä¾‹ï¼š

        ç”¨æˆ·è¾“å…¥ï¼šæŸ¥è¯¢ç”¨æˆ·idä¸ºu_456çš„ç”¨æˆ·ä¿¡æ¯
        è¿”å›ï¼š
        {{"method": "GET", "path": "/api/v1/users/u_456"}}

        ç”¨æˆ·è¾“å…¥ï¼šå¸®æˆ‘ç»™ç”¨æˆ·123åˆ›å»ºä¸€ä¸ªè®¢å•ï¼Œä¹°3ä¸ªå•†å“ç¼–å·ä¸ºp_888çš„å•†å“ï¼Œå¤‡æ³¨å†™åŠ æ€¥å¤„ç†
        è¿”å›ï¼š
        {{"method": "POST", "path": "/api/v1/orders", "body": {{"user_id": "123", "product_id": "p_888", "quantity": 3, "note": "åŠ æ€¥å¤„ç†"}}}}

        ç”¨æˆ·è¾“å…¥ï¼šæŠŠç”¨æˆ·ç¼–å·æ˜¯u_999çš„è´¦æˆ·åˆ æ‰
        è¿”å›ï¼š
        {{"method": "DELETE", "path": "/api/v1/users/u_999"}}
        âš ï¸ æ³¨æ„ï¼šä¸è¦ä½¿ç”¨ markdown è¯­æ³•åŒ…è£¹ï¼ˆå¦‚ ```jsonï¼‰ï¼Œå¦åˆ™å°†æ— æ³•è¯†åˆ«å¹¶æŠ¥é”™ï¼
        """
            ),
            HumanMessagePromptTemplate.from_template("ç”¨æˆ·éœ€æ±‚: {user_query}")
        ])


        # æ„é€ æ—  memory çš„ chain
        self.api_chain = LLMChain(
            llm=self.llm,
            prompt=self.prompt_template,
            verbose=True
        )

    def retrieve_apis(self, query: str, top_k=5):
        """æ‰§è¡Œ API æ£€ç´¢"""
        return self.vsm.enhanced_similarity_search(query, k=top_k, use_reranking=True)

    def query_to_api_json(self, query: str, override_params: Optional[dict] = None) -> dict:
        """å°†è‡ªç„¶è¯­è¨€ç”¨æˆ·è¯·æ±‚è½¬æ¢ä¸ºç¬¦åˆè§„èŒƒçš„ JSON è¯·æ±‚ä½“"""
        results = self.retrieve_apis(query)
        if not results:
            return {"status": "error", "message": "æœªæ‰¾åˆ°ç›¸å…³æ¥å£"}

        top_doc = results[0][0]
        metadata = top_doc.metadata
        params = json.loads(metadata["params_json"])

        # æ„å»º LLMChain è¾“å…¥
        inputs = {
            "name": metadata["name"],
            "description": metadata["description"],
            "method": metadata["method"],
            "endpoint": metadata["endpoint"],
            "params_json": json.dumps(params, ensure_ascii=False),
            "user_query": query,
        }

        # è°ƒç”¨å¤§æ¨¡å‹
        response = self.api_chain.invoke(inputs)
        print("ğŸ§ª Raw response from chain:", response)

        raw_text = response.get("text", "").strip()

        # æ¸…ç† markdown è¯­æ³•æˆ–æ„å¤–åŒ…è£¹
        if raw_text.startswith("```"):
            raw_text = re.sub(r"^```[a-zA-Z]*\n?", "", raw_text)
            raw_text = re.sub(r"\n?```$", "", raw_text)

        raw_text = raw_text.strip()

        try:
            parsed = json.loads(raw_text)
            # æ£€æŸ¥å¿…é¡»å­—æ®µ
            missing_fields = []
            for field in ["method", "path"]:
                if field not in parsed:
                    missing_fields.append(field)
            if missing_fields:
                parsed["missing"] = missing_fields
            return parsed
        except Exception as e:
            return {
                "status": "error",
                "message": f"è§£ææ¨¡å‹å“åº”å¤±è´¥: {str(e)}",
                "raw": raw_text
            }

app = FastAPI()

# å®ä¾‹åŒ–ä¸€æ¬¡ï¼Œé¿å…æ¯æ¬¡è¯·æ±‚éƒ½åŠ è½½æ¨¡å‹
agent = ApiRagAgent()

@app.post("/api/query")
async def query_api(request: Request):
    data = await request.json()
    query = data.get("query", "")
    if not query:
        return JSONResponse({"status": "error", "message": "ç¼ºå°‘ query å‚æ•°"}, status_code=400)
    result = agent.query_to_api_json(query)
    return JSONResponse(result)

if __name__ == "__main__":
    # å¯åŠ¨FastAPIæœåŠ¡
    uvicorn.run("api_rag_agent:app", host="0.0.0.0", port=8000, reload=True)